"""
æ¡ä»¶åˆ†æ”¯å·¥ä½œæµç¤ºä¾‹ã€‚
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ConditionalBranchNodeå®ç°åŸºäºå†…å®¹çš„åŠ¨æ€åˆ†æ”¯ã€‚

----------------------------------------
ç¤ºä¾‹è¾“å‡ºï¼šï¼ˆè¾“å…¥ï¼šå½é‡Œå’•å™œåŠˆé‡Œå•ªå•¦å—·å—·å—·ï¼‰
----------------------------------------

--- å¤„ç†ç»“æœ ---
åˆ†ç±»: Daily
ç½®ä¿¡åº¦: 0.5
åŸå› : The input consists of nonsensical or playful sounds, which are more likely to occur in casual daily conversation rather than in an educational context.
å›ç­”: å“ˆå“ˆï¼Œçœ‹æ¥ä½ æ­£åœ¨ç”¨ä¸€ç»„è¶…æœ‰è¶£çš„æ‹Ÿå£°è¯æ”¾é£è‡ªæˆ‘å‘€ï¼ğŸ¤£ å¦‚æœæ˜¯æƒ³è¡¨è¾¾å¼€å¿ƒã€çƒ¦èºã€æˆ–è€…å•çº¯æƒ³ç© å£°éŸ³æ¸¸æˆâ€”â€”æˆ‘éƒ½å‡†å¤‡å¥½å•¦ï¼éœ€è¦å¸®å¿™ç¿»è¯‘æˆâ€œäººç±»è¯­â€ï¼Œè¿˜æ˜¯æƒ³ä¸€èµ·åˆ›ä½œä¸€é¦–å™¼é‡Œå•ªå•¦äº¤å“è¯—ï¼ŸğŸµ ï¼ˆæ‚„æ‚„è¯´ ï¼šå—·å—·å—·ç‰¹åˆ«é€‚åˆç”¨æ¥æ¨¡ä»¿å°æé¾™å“¦~ ğŸ¦–ï¼‰
"""
import sys
import os

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

# å¯¼å…¥æ‰€éœ€ç»„ä»¶
from src.workflow.base import WorkflowContext
from src.workflow.engine import Workflow
from src.workflow.nodes.start_node import StartNode
from src.workflow.nodes.llm_node import LLMNode
from src.workflow.nodes.end_node import EndNode
from src.workflow.nodes.conditional_branch_node import ConditionalBranchNode, ClassDefinition
from src.llm.deepseek_client import DeepSeekClient

def run_conditional_branch_workflow():
    """è¿è¡Œæ¡ä»¶åˆ†æ”¯å·¥ä½œæµç¤ºä¾‹"""
    
    # è·å– DeepSeek API å¯†é’¥
    api_key = os.environ.get("DEEPSEEK_API_KEY")
    if not api_key:
        print("é”™è¯¯: DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡åå†è¿è¡Œï¼Œä¾‹å¦‚ï¼š")
        print("export DEEPSEEK_API_KEY='your-api-key-here'  # Linux/Mac")
        print("æˆ–")
        print("set DEEPSEEK_API_KEY=your-api-key-here  # Windows")
        return None
    
    # åˆ›å»º DeepSeek å®¢æˆ·ç«¯å®ä¾‹
    deepseek_llm = DeepSeekClient(api_key=api_key, model="deepseek-chat")
    print(f"å·²åˆ›å»ºDeepSeekå®¢æˆ·ç«¯ï¼Œä½¿ç”¨æ¨¡å‹: {deepseek_llm.model}")

    # å®šä¹‰æµå¼è¾“å‡ºçš„å›è°ƒå‡½æ•°
    def stream_callback(text_chunk):
        """å¤„ç†æµå¼è¾“å‡ºçš„æ–‡æœ¬ç‰‡æ®µ"""
        print(text_chunk, end="", flush=True)

    # å®šä¹‰åˆ†ç±»
    classes = [
        ClassDefinition(
            name="Educational",
            description="æ•™è‚²ç›¸å…³çš„æé—®æˆ–é™ˆè¿°",
            next_node_id="educational_handler",
            examples=["ä»€ä¹ˆæ˜¯å¾®ç§¯åˆ†?", "å¦‚ä½•å­¦å¥½è‹±è¯­?"]
        ),
        ClassDefinition(
            name="Daily",
            description="æ—¥å¸¸ç”Ÿæ´»å¯¹è¯",
            next_node_id="daily_handler",
            examples=["ä»Šå¤©å¤©æ°”çœŸå¥½", "æ™šé¥­åƒä»€ä¹ˆ?"]
        )
    ]

    # å®šä¹‰é»˜è®¤åˆ†ç±»ï¼ˆå…œåº•è·¯ç”±ï¼‰
    default_class = ClassDefinition(
        name="General",
        description="æ— æ³•æ˜ç¡®åˆ†ç±»çš„ä¸€èˆ¬å¯¹è¯",
        next_node_id="general_handler"
    )

    # å®šä¹‰èŠ‚ç‚¹
    start_node = StartNode(
        node_id="start", 
        node_name="Start", 
        output_variable_names=["user_query"],
        next_node_id="classifier"  # è®¾ç½®StartNodeçš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
    )
    
    # æ¡ä»¶åˆ†æ”¯èŠ‚ç‚¹
    branch_node = ConditionalBranchNode(
        node_id="classifier",
        node_name="Query Classifier",
        classes=classes,
        input_variable_name="user_query",
        llm_client=deepseek_llm,
        default_class=default_class,
        output_reason=True
    )
    
    # æ•™è‚²ç±»å¤„ç†èŠ‚ç‚¹
    educational_node = LLMNode(
        node_id="educational_handler",
        node_name="Educational Query Handler",
        system_prompt_template="è¿™æ˜¯ä¸€ä¸ªæ•™è‚²ç›¸å…³é—®é¢˜ã€‚è¯·è¯¦ç»†è§£ç­”: {user_query}",
        output_variable_name="response",
        llm_client=deepseek_llm,
        stream=True,
        stream_callback=stream_callback,
        next_node_id="educational_end"  # æŒ‡å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹
    )
    
    # æ—¥å¸¸ç±»å¤„ç†èŠ‚ç‚¹
    daily_node = LLMNode(
        node_id="daily_handler",
        node_name="Daily Query Handler",
        system_prompt_template="è¿™æ˜¯ä¸€ä¸ªæ—¥å¸¸ç”Ÿæ´»é—®é¢˜ã€‚è¯·å‹å¥½å›ç­”: {user_query}",
        output_variable_name="response",
        llm_client=deepseek_llm,
        stream=True,
        stream_callback=stream_callback,
        next_node_id="daily_end"  # æŒ‡å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹
    )
    
    # é€šç”¨ç±»å¤„ç†èŠ‚ç‚¹
    general_node = LLMNode(
        node_id="general_handler",
        node_name="General Query Handler",
        system_prompt_template="è¯·å›ç­”è¿™ä¸ªä¸€èˆ¬æ€§é—®é¢˜: {user_query}",
        output_variable_name="response",
        llm_client=deepseek_llm,
        stream=True,
        stream_callback=stream_callback,
        next_node_id="general_end"  # æŒ‡å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹
    )
    
    # ä¸ºæ¯ä¸ªåˆ†æ”¯åˆ›å»ºç‹¬ç«‹çš„ç»“æŸèŠ‚ç‚¹
    educational_end = EndNode(
        node_id="educational_end",
        node_name="Educational End",
        input_variable_names=["response"]
    )

    daily_end = EndNode(
        node_id="daily_end",
        node_name="Daily End",
        input_variable_names=["response"]
    )

    general_end = EndNode(
        node_id="general_end",
        node_name="General End",
        input_variable_names=["response"]
    )

    # åˆ›å»ºå·¥ä½œæµå®ä¾‹
    workflow = Workflow([
        start_node,
        branch_node,
        educational_node,
        daily_node,
        general_node,
        educational_end,
        daily_end,
        general_end
    ])

    # å®šä¹‰æµ‹è¯•æŸ¥è¯¢åˆ—è¡¨
    test_queries = [
        "å½é‡Œå’•å™œåŠˆé‡Œå•ªå•¦å—·å—·å—·",
        "ä»Šå¤©å¤©æ°”çœŸå¥½",
    ]

    for query in test_queries:
        print("\n" + "="*50)
        print(f"æµ‹è¯•æŸ¥è¯¢: {query}")
        print("="*50)
        
        # è®¾ç½®åˆå§‹ä¸Šä¸‹æ–‡
        context = {"user_query": query}
        
        # æ‰§è¡Œå·¥ä½œæµ
        try:
            final_context = workflow.run(context)
            
            # è¾“å‡ºç»“æœ
            print("\n--- å¤„ç†ç»“æœ ---")
            print(f"åˆ†ç±»: {final_context['classification_result']['class_name']}")
            print(f"ç½®ä¿¡åº¦: {final_context['classification_result'].get('confidence', 'N/A')}")
            if 'classification_result_reason' in final_context:
                print(f"åŸå› : {final_context['classification_result_reason']}")
            print(f"å›ç­”: {final_context['response']}")
        except Exception as e:
            print(f"\nå·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")

    print("\næ¡ä»¶åˆ†æ”¯å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼")
    return final_context  # è¿”å›æœ€åä¸€ä¸ªæŸ¥è¯¢çš„æœ€ç»ˆä¸Šä¸‹æ–‡

if __name__ == "__main__":
    run_conditional_branch_workflow()
